# @Author       : Ruopeng Gao
# @Description  : Config for training DanceTrack.
#                 We change some parameters compared with our paper, looking forward more stable training convergence.

GIT_VERSION:

MODE: train
CONFIG_PATH:
VISUALIZE: False
AVAILABLE_GPUS: 0,
DEVICE: cuda
OUTPUTS_DIR: ./outputs/putr_dancetrack/
USE_DISTRIBUTED: False

RESUME:
RESUME_SCHEDULER: True
MULTI_CHECKPOINT: False



# About data processing
DATASET: DanceTrack
USE_MOTSYNTH:
USE_CROWDHUMAN:
MOTSYNTH_RATE:
DATA_ROOT:
DATA_PATH:
NUM_WORKERS: 8
BATCH_SIZE: 4
ACCUMULATION_STEPS: 32
COCO_SIZE: False
OVERFLOW_BBOX: False
REVERSE_CLIP: 0.0
SEND_IMG: True

# About model
DIM: 512
N_LAYERS: 6
N_HEADS: 8
NORM_EPS: 1.0e-5
PATCH_GRID: 64
MAX_SEQ_LEN: 4096

# Pretrain model
PRETRAINED_MODEL: /home/lcw/hdd/projects/PuTR/论文数据/mix/train_2024-04-24-11-53/checkpoint_6.pth

# Sampling setting
SAMPLE_STEPS: [1, 2]
SAMPLE_LENGTHS: [32, 32, 32]
SAMPLE_MODES: [random_interval]
SAMPLE_INTERVALS: [10]

# Training setting
SEED: 42
EPOCHS: 3
DROP_OUT: 0.0
LR: 1.0e-4
WEIGHT_DECAY: 0.0005
CLIP_MAX_NORM: 1.0
LR_SCHEDULER: Cosine
LR_DROP_RATE:
LR_DROP_MILESTONES:
